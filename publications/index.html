<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Yi Hao Chan </title> <meta name="author" content="Yi Hao Chan"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://yihao001.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Yi Hao</span> Chan </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <p>During my PhD studies, I developed techniques to model small and high dimensional multimodal datasets (i.e. large p, small n). Specifically, custom graph neural networks and explainable AI techniques were created to derive connectome-based disease biomarkers (i.e. brain regions/connections affected by diseases). Our techniques go beyond existing class-wide approaches by producing <strong>individualised</strong> and <strong>subgroup-specific insights</strong> that would be more clinically relevant than existing solutions. Along the way, we proposed solutions to address problems such as inter-site variability, disease heterogeneity and multimodal fusion.</p> <p>The next stage of my research is focused on the <strong>robustness</strong> of these explanations. Most existing studies do not robustly evaluate the salient features highlighted by their algorithms. However, doing so is key towards improving our understanding of neurological disorders. Many obstacles exist, including problems related to data quality (e.g. there’s no agreement on the best fMRI preprocessing pipeline), the perception that neural networks are black boxes and the limited repertoire of tools we have to evaluate explainable AI techniques. We’re actively working on this and if you are keen to collaborate, do send me an email! :)</p> <p>Beyond connectomes, I have also worked on anatomical brain imaging (i.e. lesion / tissue segmentation) and more pragmatic forms of vision-language models for radiology AI applications. More details will be shared here at a more appropriate time.</p> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Evaluation</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/review-480.webp 480w,/assets/img/publication_preview/review-800.webp 800w,/assets/img/publication_preview/review-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/review.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="review.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="chan2024discovering" class="col-sm-8"> <div class="title">Discovering robust biomarkers of neurological disorders from functional MRI using graph neural networks: A Review</div> <div class="author"> <em>Yi Hao Chan</em>, Deepank Girish, Sukrit Gupta , and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Jing Xia, Chockalingam Kasi, Yinan He, Conghao Wang, Jagath C Rajapakse' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>arXiv preprint arXiv:2405.00577</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2405.00577" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Graph neural networks (GNN) have emerged as a popular tool for modelling functional magnetic resonance imaging (fMRI) datasets. Many recent studies have reported significant improvements in disorder classification performance via more sophisticated GNN designs and highlighted salient features that could be potential biomarkers of the disorder. In this review, we provide an overview of how GNN and model explainability techniques have been applied on fMRI datasets for disorder prediction tasks, with a particular emphasis on the robustness of biomarkers produced for neurodegenerative diseases and neuropsychiatric disorders. We found that while most studies have performant models, salient features highlighted in these studies vary greatly across studies on the same disorder and little has been done to evaluate their robustness. To address these issues, we suggest establishing new standards that are based on objective evaluation metrics to determine the robustness of these potential biomarkers. We further highlight gaps in the existing literature and put together a prediction-attribution-evaluation framework that could set the foundations for future research on improving the robustness of potential biomarkers discovered via GNNs.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">chan2024discovering</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Discovering robust biomarkers of neurological disorders from functional MRI using graph neural networks: A Review}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chan, Yi Hao and Girish, Deepank and Gupta, Sukrit and Xia, Jing and Kasi, Chockalingam and He, Yinan and Wang, Conghao and Rajapakse, Jagath C}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2405.00577}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Segmentation</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/access-480.webp 480w,/assets/img/publication_preview/access-800.webp 800w,/assets/img/publication_preview/access-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/access.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="access.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="rajapakse2024two" class="col-sm-8"> <div class="title">Two-stage approach to intracranial hemorrhage segmentation from head CT images</div> <div class="author"> Jagath C Rajapakse, Chun Hung How, <em>Yi Hao Chan</em> , and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Luke Chin Peng Hao, Abhinandan Padhi, Vivek Adrakatti, Iram Khan, Tchoyoson Lim' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>IEEE Access</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/chapter/10.1007/978-3-031-16431-6_42" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Intracranial hemorrhage (ICH) is an emergency and a potentially life-threatening condition. Automated segmentation of ICH from head CT images can provide clinicians with volumetric measures that can be used for diagnosis and decision support for treatment procedures. Existing solutions typically involve training deep learning models to perform segmentation directly on the whole CT image. However, datasets with segmentation masks are typically very small in comparison with datasets with bounding boxes. Thus, we propose a two-stage approach that utilizes both bounding boxes and segmentation masks to help improve segmentation performance. In the first stage, ICH regions are detected and localized with bounding boxes surrounding the lesion by using a supervised YOLOv5 object detector. In the second stage, the localized ICH foreground is automatically segmented using TransDeepLab, an attention-based transformer network. Although we utilize both ground-truth bounding boxes and segmentation masks, different datasets can be used to train each stage. There is no requirement for pairing up bounding boxes and segmentation masks to train the model. Since bounding box annotations are available in larger quantities than segmentation masks, our approach allows these large datasets of bounding boxes to be used to improve ICH segmentation performance. On our dataset of segmentation masks, we demonstrated that our proposed two-stage YOLOv5+ TransDeepLab model outperformed segmentation methods such as SegResNet by 8% in terms of Dice score. Given ground truth bounding boxes, a Dice score of 0.769 is achieved, outperforming state-of-the-art methods such as nnU-Net. In sum, our proposed two-stage approach produces more accurate binary segmentation of ICH for neuroradiologists and these improved measurements could potentially aid their clinical decision-making process.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">rajapakse2024two</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Two-stage approach to intracranial hemorrhage segmentation from head CT images}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Rajapakse, Jagath C and How, Chun Hung and Chan, Yi Hao and Hao, Luke Chin Peng and Padhi, Abhinandan and Adrakatti, Vivek and Khan, Iram and Lim, Tchoyoson}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Access}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Multimodal</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/xj_icassp-480.webp 480w,/assets/img/publication_preview/xj_icassp-800.webp 800w,/assets/img/publication_preview/xj_icassp-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/xj_icassp.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="xj_icassp.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xia2024brain" class="col-sm-8"> <div class="title">Brain Structure-Function Interaction Network for Fluid Cognition Prediction</div> <div class="author"> Jing Xia, <em>Yi Hao Chan</em>, Deepank Girish , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Jagath C Rajapakse' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> <strong>(Oral)</strong> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/10448348" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Predicting fluid cognition via neuroimaging data is essential for understanding the neural mechanisms underlying various complex cognitions in the human brain. Both brain functional connectivity (FC) and structural connectivity (SC) provide distinct neural mechanisms for fluid cognition. In addition, interactions between SC and FC within distributed association regions are related to improvements in fluid cognition. However, existing learning-based methods that leverage both modality-specific embeddings and high-order interactions between the two modalities for prediction are scarce. To tackle these challenges, this study proposes an end-to-end brain structure-function interaction network that incorporates both modality-specific embeddings and structure-function interactions to predict fluid cognition. In this model, we generate embeddings from both FC and SC separately using a graph convolution encoder-decoder module. Subsequently, we learn the interactive weights between corresponding regions of FC and SC, reflecting the coupling strength, by employing an interactive module on the embeddings of both modalities. A novel graph structure - utilizing modality-specific embeddings and interactive weights - is constructed and used for the final prediction. Experimental results demonstrate that our proposed method outperforms other state-of-the-art methods employed on uni-modal and multi-modal brain features. We further identify that strong structure-function coupling in the inferior frontal, postcentral, superior temporal and cingulate cortices are associated with fluid intelligence.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">xia2024brain</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Brain Structure-Function Interaction Network for Fluid Cognition Prediction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xia, Jing and Chan, Yi Hao and Girish, Deepank and Rajapakse, Jagath C}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1706--1710}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Biomarkers</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/subtype-480.webp 480w,/assets/img/publication_preview/subtype-800.webp 800w,/assets/img/publication_preview/subtype-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/subtype.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="subtype.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="chan2024subtype" class="col-sm-8"> <div class="title">Subtype-Specific Biomarkers of Alzheimer’s Disease from Anatomical and Functional Connectomes via Graph Neural Networks</div> <div class="author"> <em>Yi Hao Chan</em>, Jun Liang Ang, Sukrit Gupta , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Yinan He, Jagath C Rajapakse' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> <strong>(Oral)</strong> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/10447054" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Heterogeneity is present in Alzheimer’s disease (AD), making it challenging to study. To address this, we propose a graph neural network (GNN) approach to identify disease subtypes from magnetic resonance imaging (MRI) and functional MRI (fMRI) scans. Subtypes are identified by encoding the patients’ scans in brain graphs (via cortical similarity networks) and clustering the representations learnt by the GNN. These subtyping information are used to construct population graphs for an ensemble of local networks, each producing intermediate predictions that are subsequently combined to produce the model’s final decision. Using MRI and fMRI scans from two datasets on AD, we demonstrate that our proposed architecture outperforms existing methods. Three subtypes of AD were identified and left cuneus was found to be a consistent class-wide biomarker. Subtype-specific biomarkers produced by our method further revealed deeper insights, including a unique subtype with significant degeneration in the left isthmus cingulate cortex.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chan2024subtype</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Subtype-Specific Biomarkers of Alzheimer’s Disease from Anatomical and Functional Connectomes via Graph Neural Networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chan, Yi Hao and Ang, Jun Liang and Gupta, Sukrit and He, Yinan and Rajapakse, Jagath C}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2195--2199}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Biomarkers</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/shred3-480.webp 480w,/assets/img/publication_preview/shred3-800.webp 800w,/assets/img/publication_preview/shred3-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/shred3.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="shred3.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="chan2023elucidating" class="col-sm-8"> <div class="title">Elucidating salient site-specific functional connectivity features and site-invariant biomarkers in schizophrenia via deep neural networks</div> <div class="author"> <em>Yi Hao Chan</em>, Wei Chee Yew, Qian Hui Chew , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Kang Sim, Jagath C Rajapakse' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Scientific Reports</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.nature.com/articles/s41598-023-48548-w" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/SCSE-Biomedical-Computing-Group/SHRED" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Schizophrenia is a highly heterogeneous disorder and salient functional connectivity (FC) features have been observed to vary across study sites, warranting the need for methods that can differentiate between site-invariant FC biomarkers and site-specific salient FC features. We propose a technique named Semi-supervised learning with data HaRmonisation via Encoder-Decoder-classifier (SHRED) to examine these features from resting state functional magnetic resonance imaging scans gathered from four sites. Our approach involves an encoder-decoder-classifier architecture that simultaneously performs data harmonisation and semi-supervised learning (SSL) to deal with site differences and labelling inconsistencies across sites respectively. The minimisation of reconstruction loss from SSL was shown to improve model performance even within small datasets whilst data harmonisation often led to lower model generalisability, which was unaffected using the SHRED technique. We show that our proposed model produces site-invariant biomarkers, most notably the connection between transverse temporal gyrus and paracentral lobule. Site-specific salient FC features were also elucidated, especially implicating the paracentral lobule for our local dataset. Our examination of these salient FC features demonstrates how site-specific features and site-invariant biomarkers can be differentiated, which can deepen our understanding of the neurobiology of schizophrenia.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">chan2023elucidating</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Elucidating salient site-specific functional connectivity features and site-invariant biomarkers in schizophrenia via deep neural networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chan, Yi Hao and Yew, Wei Chee and Chew, Qian Hui and Sim, Kang and Rajapakse, Jagath C}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Scientific Reports}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{13}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{21047}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Nature Publishing Group UK London}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Multimodal</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/yt-480.webp 480w,/assets/img/publication_preview/yt-800.webp 800w,/assets/img/publication_preview/yt-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/yt.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="yt.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zhang2023multi" class="col-sm-8"> <div class="title">Multi-modal graph neural network for early diagnosis of Alzheimer’s disease from sMRI and PET scans</div> <div class="author"> Yanteng Zhang, Xiaohai He, <em>Yi Hao Chan</em> , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Qizhi Teng, Jagath C Rajapakse' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Computers in Biology and Medicine</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/abs/pii/S001048252300793X" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>In recent years, deep learning models have been applied to neuroimaging data for early diagnosis of Alzheimer’s disease (AD). Structural magnetic resonance imaging (sMRI) and positron emission tomography (PET) images provide structural and functional information about the brain, respectively. Combining these features leads to improved performance than using a single modality alone in building predictive models for AD diagnosis. However, current multi-modal approaches in deep learning, based on sMRI and PET, are mostly limited to convolutional neural networks, which do not facilitate integration of both image and phenotypic information of subjects. We propose to use graph neural networks (GNN) that are designed to deal with problems in non-Euclidean domains. In this study, we demonstrate how brain networks are created from sMRI or PET images and can be used in a population graph framework that combines phenotypic information with imaging features of the brain networks. Then, we present a multi-modal GNN framework where each modality has its own branch of GNN and a technique that combines the multi-modal data at both the level of node vectors and adjacency matrices. Finally, we perform late fusion to combine the preliminary decisions made in each branch and produce a final prediction. As multi-modality data becomes available, multi-source and multi-modal is the trend of AD diagnosis. We conducted explorative experiments based on multi-modal imaging data combined with non-imaging phenotypic information for AD diagnosis and analyzed the impact of phenotypic information on diagnostic performance. Results from experiments demonstrated that our proposed multi-modal approach improves performance for AD diagnosis. Our study also provides technical reference and support the need for multivariate multi-modal diagnosis methods.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zhang2023multi</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multi-modal graph neural network for early diagnosis of Alzheimer's disease from sMRI and PET scans}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Yanteng and He, Xiaohai and Chan, Yi Hao and Teng, Qizhi and Rajapakse, Jagath C}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computers in Biology and Medicine}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{164}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{107328}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Biomarkers</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/shred-480.webp 480w,/assets/img/publication_preview/shred-800.webp 800w,/assets/img/publication_preview/shred-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/shred.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="shred.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="chan2022semi" class="col-sm-8"> <div class="title">Semi-supervised learning with data harmonisation for biomarker discovery from resting state fMRI</div> <div class="author"> <em>Yi Hao Chan</em>, Wei Chee Yew, and Jagath C Rajapakse </div> <div class="periodical"> <em>In International Conference on Medical Image Computing and Computer-Assisted Intervention</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/chapter/10.1007/978-3-031-16431-6_42" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/SCSE-Biomedical-Computing-Group/SHRED" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Computational models often overfit on neuroimaging datasets (which are high-dimensional and consist of small sample sizes), resulting in poor inferences such as ungeneralisable biomarkers. One solution is to pool datasets (of similar disorders) from other sites to augment the small dataset, but such efforts have to handle variations introduced by site effects and inconsistent labelling. To overcome these issues, we propose an encoder-decoder-classifier architecture that combines semi-supervised learning with harmonisation of data across sites. The architecture is trained end-to-end via a novel multi-objective loss function. Using the architecture on multi-site fMRI datasets such as ADHD-200 and ABIDE, we obtained significant improvement on classification performance and showed how site-invariant biomarkers were disambiguated from site-specific ones. Our findings demonstrate the importance of accounting for both site effects and labelling inconsistencies when combining datasets from multiple sites to overcome the paucity of data. With the proliferation of neuroimaging research conducted on retrospectively aggregated datasets, our architecture offers a solution to handle site differences and labelling inconsistencies in such datasets. Code is available at https://github.com/SCSE-Biomedical-Computing-Group/SHRED.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chan2022semi</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Semi-supervised learning with data harmonisation for biomarker discovery from resting state fMRI}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chan, Yi Hao and Yew, Wei Chee and Rajapakse, Jagath C}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Medical Image Computing and Computer-Assisted Intervention}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{441--451}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Multimodal</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/join-480.webp 480w,/assets/img/publication_preview/join-800.webp 800w,/assets/img/publication_preview/join-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/join.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="join.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="chan2022combining" class="col-sm-8"> <div class="title">Combining neuroimaging and omics datasets for disease classification using graph neural networks</div> <div class="author"> <em>Yi Hao Chan</em>, Conghao Wang, Wei Kwek Soh , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Jagath C Rajapakse' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Frontiers in Neuroscience</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2022.866666/full" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Both neuroimaging and genomics datasets are often gathered for the detection of neurodegenerative diseases. Huge dimensionalities of neuroimaging data as well as omics data pose tremendous challenge for methods integrating multiple modalities. There are few existing solutions that can combine both multi-modal imaging and multi-omics datasets to derive neurological insights. We propose a deep neural network architecture that combines both structural and functional connectome data with multi-omics data for disease classification. A graph convolution layer is used to model functional magnetic resonance imaging (fMRI) and diffusion tensor imaging (DTI) data simultaneously to learn compact representations of the connectome. A separate set of graph convolution layers are then used to model multi-omics datasets, expressed in the form of population graphs, and combine them with latent representations of the connectome. An attention mechanism is used to fuse these outputs and provide insights on which omics data contributed most to the model’s classification decision. We demonstrate our methods for Parkinson’s disease (PD) classification by using datasets from the Parkinson’s Progression Markers Initiative (PPMI). PD has been shown to be associated with changes in the human connectome and it is also known to be influenced by genetic factors. We combine DTI and fMRI data with multi-omics data from RNA Expression, Single Nucleotide Polymorphism (SNP), DNA Methylation and non-coding RNA experiments. A Matthew Correlation Coefficient of greater than 0.8 over many combinations of multi-modal imaging data and multi-omics data was achieved with our proposed architecture. To address the paucity of paired multi-modal imaging data and the problem of imbalanced data in the PPMI dataset, we compared the use of oversampling against using CycleGAN on structural and functional connectomes to generate missing imaging modalities. Furthermore, we performed ablation studies that offer insights into the importance of each imaging and omics modality for the prediction of PD. Analysis of the generated attention matrices revealed that DNA Methylation and SNP data were the most important omics modalities out of all the omics datasets considered. Our work motivates further research into imaging genetics and the creation of more multi-modal imaging and multi-omics datasets to study PD and other complex neurodegenerative diseases.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">chan2022combining</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Combining neuroimaging and omics datasets for disease classification using graph neural networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chan, Yi Hao and Wang, Conghao and Soh, Wei Kwek and Rajapakse, Jagath C}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Frontiers in Neuroscience}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{16}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{866666}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Frontiers Media SA}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Biomarkers</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/lean-480.webp 480w,/assets/img/publication_preview/lean-800.webp 800w,/assets/img/publication_preview/lean-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/lean.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="lean.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="gupta2021obtaining" class="col-sm-8"> <div class="title">Obtaining leaner deep neural networks for decoding brain functional connectome in a single shot</div> <div class="author"> Sukrit Gupta<sup>*</sup>, <em>Yi Hao Chan<sup>*</sup></em>, Jagath C Rajapakse , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Alzheimer’s Disease Neuroimaging Initiative, others' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Co-first authors"> </i> </div> <div class="periodical"> <em>Neurocomputing</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231221000977" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/SCSE-Biomedical-Computing-Group/LEAN_CLIP" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Neuroscientific knowledge points to the presence of redundancy in the correlations of the brain’s functional activity. These redundancies can be removed to mitigate the problem of overfitting when deep neural network (DNN) models are used to classify neuroimaging datasets. We propose an algorithm that removes insignificant nodes of DNNs in a layerwise manner and then adds a subset of correlated features in a single shot. When performing experiments with functional MRI datasets for classifying patients from healthy controls, we were able to obtain simpler and more generalizable DNNs. The obtained DNNs maintained a similar performance as the full network with only around 2% of the initial trainable parameters. Further, we used the trained network to identify salient brain regions and connections from functional connectome for multiple brain disorders. The identified biomarkers were found to closely correspond to previously known disease biomarkers. The proposed methods have cross-modal applications in obtaining leaner DNNs that seem to fit neuroimaging data better. The corresponding code is available at https://github.com/SCSE-Biomedical-Computing-Group/LEAN_CLIP.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">gupta2021obtaining</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Obtaining leaner deep neural networks for decoding brain functional connectome in a single shot}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gupta, Sukrit and Chan, Yi Hao and Rajapakse, Jagath C and Initiative, Alzheimer’s Disease Neuroimaging and others}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Neurocomputing}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{453}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{326--336}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Time Series</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/spot-480.webp 480w,/assets/img/publication_preview/spot-800.webp 800w,/assets/img/publication_preview/spot-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/spot.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="spot.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="chan2020decoding" class="col-sm-8"> <div class="title">Decoding task states by spotting salient patterns at time points and brain regions</div> <div class="author"> <em>Yi Hao Chan</em>, Sukrit Gupta, LL Chamara Kasun , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Jagath C Rajapakse' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Machine Learning in Clinical Neuroimaging and Radiogenomics in Neuro-oncology: Third International Workshop, MLCN 2020, and Second International Workshop, RNO-AI 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4–8, 2020, Proceedings 3</em> , 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/chapter/10.1007/978-3-030-66843-3_9" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/SCSE-Biomedical-Computing-Group/SPOTS" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>During task performance, brain states change dynamically and can appear recurrently. Recently, recurrent neural networks (RNN) have been used for identifying functional signatures underlying such brain states from task functional Magnetic Resonance Imaging (fMRI) data. While RNNs only model temporal dependence between time points, brain task decoding needs to model temporal dependencies of the underlying brain states. Furthermore, as only a subset of brain regions are involved in task performance, it is important to consider subsets of brain regions for brain decoding. To address these issues, we present a customised neural network architecture, Salient Patterns Over Time and Space (SPOTS), which not only captures dependencies of brain states at different time points but also pays attention to key brain regions associated with the task. On language and motor task data gathered in the Human Connectome Project, SPOTS improves brain state prediction by 17% to 40% as compared to the baseline RNN model. By spotting salient spatio-temporal patterns, SPOTS is able to infer brain states even on small time windows of fMRI data, which the present state-of-the-art methods struggle with. This allows for quick identification of abnormal task-fMRI scans, leading to possible future applications in task-fMRI data quality assurance and disease detection. Code is available at https://github.com/SCSE-Biomedical-Computing-Group/SPOTS.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chan2020decoding</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Decoding task states by spotting salient patterns at time points and brain regions}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chan, Yi Hao and Gupta, Sukrit and Kasun, LL Chamara and Rajapakse, Jagath C}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Machine Learning in Clinical Neuroimaging and Radiogenomics in Neuro-oncology: Third International Workshop, MLCN 2020, and Second International Workshop, RNO-AI 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4--8, 2020, Proceedings 3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{88--97}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Biomarkers</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/rfe-480.webp 480w,/assets/img/publication_preview/rfe-800.webp 800w,/assets/img/publication_preview/rfe-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/rfe.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="rfe.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="gupta2019decoding" class="col-sm-8"> <div class="title">Decoding brain functional connectivity implicated in AD and MCI</div> <div class="author"> Sukrit Gupta, <em>Yi Hao Chan</em>, Jagath C Rajapakse , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Alzheimer’s Disease Neuroimaging Initiative' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In International conference on medical image computing and computer-assisted intervention</em> <strong>(Oral)</strong> , 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/chapter/10.1007/978-3-030-66843-3_9" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Deep neural networks have been demonstrated to extract high level features from neuroimaging data when classifying brain states. Identifying salient features characterizing brain states further refines the focus of clinicians and allows design of better diagnostic systems. We demonstrate this while performing classification of resting-state functional magnetic resonance imaging (fMRI) scans of patients suffering from Alzheimer’s Disease (AD) and Mild Cognitive Impairment (MCI), and Cognitively Normal (CN) subjects from the Alzheimer’s Disease Neuroimaging Initiative (ADNI). We use a 5-layer feed-forward deep neural network (DNN) to derive relevance scores of input features and show that an empirically selected subset of features improves accuracy scores for patient classification. The common distinctive salient brain regions were in the uncus and medial temporal lobe which closely correspond with previous studies. The proposed methods have cross-modal applications with several neuropsychiatric disorders.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">gupta2019decoding</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Decoding brain functional connectivity implicated in AD and MCI}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gupta, Sukrit and Chan, Yi Hao and Rajapakse, Jagath C and Initiative, Alzheimer’s Disease Neuroimaging}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International conference on medical image computing and computer-assisted intervention}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{781--789}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Yi Hao Chan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-teaching",title:"teaching",description:"",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"post-revamp",title:"Revamp",description:"refresh!",section:"Posts",handler:()=>{window.location.href="/blog/2024/revamp/"}},{id:"post-confusion-matrices-in-sklearn",title:"Confusion Matrices in sklearn",description:"confusion matrices are confusing",section:"Posts",handler:()=>{window.location.href="/blog/2020/confusion/"}},{id:"post-learning-machines",title:"Learning Machines",description:"beyond machine learning",section:"Posts",handler:()=>{window.location.href="/blog/2020/learning/"}},{id:"post-decomposing-huge-matrices",title:"Decomposing huge matrices",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2020/decompose/"}},{id:"post-repurposing-hard-disks",title:"Repurposing hard disks",description:"many parts of a crashed computer are still reusable",section:"Posts",handler:()=>{window.location.href="/blog/2019/repurpose/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"projects-class-imbalance-in-bankruptcy-prediction-tasks",title:"Class imbalance in bankruptcy prediction tasks",description:"Are deep learning models able to perform better than Altman?",section:"Projects",handler:()=>{window.location.href="/projects/bc3409_bankrupt/"}},{id:"projects-singlish-sentiment-analysis",title:"Singlish sentiment analysis",description:"Can BERT perform polarity detection on text with code-switching?",section:"Projects",handler:()=>{window.location.href="/projects/ce7455_singlish/"}},{id:"projects-licence-plate-recognition-with-motion-blur",title:"Licence plate recognition with motion blur",description:"Will CNNs still work well in such situations?",section:"Projects",handler:()=>{window.location.href="/projects/ureca_alpr/"}},{id:"teaching-cz2002-object-oriented-design-amp-programming",title:"CZ2002 Object Oriented Design & Programming",description:"AY20/21, Semester 1",section:"Teaching",handler:()=>{window.location.href="/teaching/AY2021-S1-CZ2002/"}},{id:"teaching-cx1115-introduction-to-ds-and-ai",title:"CX1115 Introduction to DS and AI",description:"AY20/21, Semester 2",section:"Teaching",handler:()=>{window.location.href="/teaching/AY2021-S2-CX1115/"}},{id:"teaching-cz4042-neural-networks-and-deep-learning",title:"CZ4042 Neural Networks and Deep Learning",description:"AY21/22, AY22/23, AY23/24",section:"Teaching",handler:()=>{window.location.href="/teaching/AY2122-S1-CZ4042/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%69%68%61%6F%30%31%39@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=68v21DIAAAAJ","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/randcogitation","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>