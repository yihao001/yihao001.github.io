<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Licence plate recognition with motion blur | Yi Hao Chan </title> <meta name="author" content="Yi Hao Chan"> <meta name="description" content="Will CNNs still work well in such situations?"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://yihao001.github.io/projects/ureca_alpr/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Yi Hao</span> Chan </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Licence plate recognition with motion blur</h1> <p class="post-description">Will CNNs still work well in such situations?</p> </header> <article> <blockquote> <p>This project was done as part of URECA in AY16/17-17/18</p> </blockquote> <h2 id="key-contributions">Key contributions</h2> <ul> <li>Created a dataset of licence plates with motion blur, containing 114,000 individual character crops</li> </ul> <h2 id="motivation">Motivation</h2> <p>OCR is pretty much a solved problem in computer vision and such tools are readily available (e.g. integrated into Mac‚Äôs Preview). However, there are several scenarios where it can still fail. One example would be the case of licence plate recognition, where cars could be swerving and travelling at high speed, resulting in only a blurred image being captured.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_preview/ureca_blur-480.webp 480w,/assets/img/project_preview/ureca_blur-800.webp 800w,/assets/img/project_preview/ureca_blur-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project_preview/ureca_blur.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Example of a blurred licence plate. </div> <p>Would it be possible to train CNNs to recognise such blurred licence plates that are indiscernible to us? Let‚Äôs find out! üîç</p> <h2 id="existing-work">Existing work</h2> <p>There are definitely papers on OCR (e.g. MNIST) and even automatic licence plate recognition (ALPR), but at that point of time, most existing works worked on clear images (or at most with a bit of blur). There are image deblurring techniques available, but most require the estimation of a blurring kernel. This is difficult to generalise since such a kernel would vary significantly depending on the environment and recording medium (e.g. relative velocity, lighting, exposure length, etc.). Thus, we want to investigate whether an automated and generalisable approach can be achieved via deep learning.</p> <h2 id="methods">Methods</h2> <p>Since there are no readily available datasets, we had to create one ourselves from scratch. Briefly, here‚Äôs how we did it:</p> <ol> <li>Record videos of moving vehicles <ul> <li>We literally sat on top of a double deck bus, sat in front and used our phones to record vehicles in front of us.</li> </ul> </li> <li>Extract frames from the videos via VLC</li> <li>Crop car plates from frames (at that time, this had to be done manually since automated methods did not work)</li> <li>Label crops (there are different kinds of car plates) <ul> <li>e.g. 1 line vs 2 lines ; different combinations of numbers and letters</li> <li>some frames will have clear images and they can be used to guide the labelling process for blurred frames</li> </ul> </li> <li>For each car plate configuration (e.g. 3-4-1, 1 line), identify the largest crop and ensure that it is straightened</li> <li>Perform affine transformation via MATLAB on the rest of the crops w.r.t the largest crop so that all crops will be aligned</li> <li>Crop out each character from the whole plate (again, this is manually done)</li> <li>Generate bounding boxes that captures about 80% of each character</li> <li>Resize the final crops to 30x30 pixels</li> </ol> <p>End product: 36 folders of crops labelled A-Z, 0-9, amounting to 114,000 individual character crops. Some characters occur less frequently, e.g. M, U, V, W and numbers are generally more well and equally represented than letters.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_preview/ureca_char-480.webp 480w,/assets/img/project_preview/ureca_char-800.webp 800w,/assets/img/project_preview/ureca_char-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project_preview/ureca_char.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Individual character crops of vehicle licence plate SBS3058R (from a public bus), from different frames (bottom row has the most blurring). </div> <p>With this dataset, we can finally train a model to perform character recognition. We used a DenseNet (at that point, it was one of the SOTA) to perform the multi-class classification task (36 classes).</p> <h2 id="results">Results</h2> <p>Quite impressively, our model was able to achieve an accuracy of 99.6%, given individual character crops. On hindsight, this could potentially be inflated by data leakage (especially since this was our first deep learning project). For example, when splitting the dataset into train and test, we might not have directly done the split for each folder and did not make sure that characters from the same licence plate are not in both the train and test splits.</p> <h2 id="future-work">Future work</h2> <p>Even if the performance is still high after ensuring that data leakage did not happen, there are still a couple of steps left before a model can be deployed. The current model requires individual character crops, but it would be too troublesome to perform this manually for every frame that needs to be investigated. One way to address this problem is to design a system that takes in a car plate as input, produce individual crops by making small strides laterally across the car plate and generate a probability map of what character the CNN guesses for every crop.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_preview/ureca_map-480.webp 480w,/assets/img/project_preview/ureca_map-800.webp 800w,/assets/img/project_preview/ureca_map-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project_preview/ureca_map.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Example of a probability map for a licence plate. </div> <p>There are some limitations in our dataset. For example, there are no ‚ÄòI‚Äôs and ‚ÄòO‚Äôs in the dataset as these letters are not used in vehicle license plates in Singapore, presumably to avoid confusing them with 0 and 1. Our dataset does consider images taken from different angles and lighting condition, but darker images are likely to be underrepresented and weather conditions (e.g. rain, cloud cover) were not thoroughly considered. Inclement weather would present a very challenging task (e.g. car plates covered by heavy rain, camera lens blurred by raindrops). Finally, the extent of motion blur might not be that great, partly due to the need to have some frames without blur. Future work would have to address these issues to produce a system that will work well in most situations.</p> <h2 id="learning-points">Learning points</h2> <p>Manual data collection is extremely labourious and going through this process makes one very appreciative of open-source datasets. There are numerous decisions that have to be made along the way, e.g.</p> <ul> <li>Format to record the labels (we decided on <code class="language-plaintext highlighter-rouge">&lt;Car plate number&gt;_&lt;Video file name&gt;_&lt;Type of car plate&gt;_&lt;Recording type&gt;_&lt;Lighting&gt;_&lt;Viewing angle&gt;_&lt;Car plate color&gt;</code>).</li> <li>Best way to store the dataset. We learnt it the very, very hard way that HDDs are awful at transferring thousands of small images. Having SSDs would make our lives much easier.</li> </ul> <p>Deep learning was beginning to get popular but was still at a rather nascent stage at that time (2016) and one of the popular frameworks then was Caffe. As freshmen, it was awfully hard to figure out how to even get it installed correctly (documentation was essentially non-existent for Windows, every line in the Makefile had to be checked carefully) and we only got it to work when Caffe 2 was released. Eventually, at a later stage, TensorFlow got popular but was still terribly hard to use as compared to what we have today (e.g. Keras, PyTorch, with extensive documentation). Looking back, I think it would have been better if we entered the field 1-2 years later. So much time was wasted to get the frameworks to work and at that time, few people knew how to get things to work. It is pretty amazing to see how far things have developed in 8 years (2016 to 2024).</p> <p>Is it an invasion of privacy, or would the benefits (e.g. safer roads if road users are deterred by the knowledge that they will be caught) outweigh the cons? I think the answer would be pretty nuanced (e.g. there‚Äôs data involved that‚Äôs somewhat PII and there is no viable way to get consent, but on the other hand it‚Äôs also publically available information) but upon reflection, this experience has guided me towards other research topics. It is probably OK to do research on it and produce a tool that would be useful for law enforcement agencies, but the data would have to be handled carefully (e.g. we did not openly release the dataset).</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2024 Yi Hao Chan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-teaching",title:"teaching",description:"",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"post-revamp",title:"Revamp",description:"refresh!",section:"Posts",handler:()=>{window.location.href="/blog/2024/revamp/"}},{id:"post-confusion-matrices-in-sklearn",title:"Confusion Matrices in sklearn",description:"confusion matrices are confusing",section:"Posts",handler:()=>{window.location.href="/blog/2020/confusion/"}},{id:"post-learning-machines",title:"Learning Machines",description:"beyond machine learning",section:"Posts",handler:()=>{window.location.href="/blog/2020/learning/"}},{id:"post-decomposing-huge-matrices",title:"Decomposing huge matrices",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2020/decompose/"}},{id:"post-repurposing-hard-disks",title:"Repurposing hard disks",description:"many parts of a crashed computer are still reusable",section:"Posts",handler:()=>{window.location.href="/blog/2019/repurpose/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"projects-class-imbalance-in-bankruptcy-prediction-tasks",title:"Class imbalance in bankruptcy prediction tasks",description:"Are deep learning models able to perform better than Altman?",section:"Projects",handler:()=>{window.location.href="/projects/bc3409_bankrupt/"}},{id:"projects-singlish-sentiment-analysis",title:"Singlish sentiment analysis",description:"Can BERT perform polarity detection on text with code-switching?",section:"Projects",handler:()=>{window.location.href="/projects/ce7455_singlish/"}},{id:"projects-licence-plate-recognition-with-motion-blur",title:"Licence plate recognition with motion blur",description:"Will CNNs still work well in such situations?",section:"Projects",handler:()=>{window.location.href="/projects/ureca_alpr/"}},{id:"teaching-cz2002-object-oriented-design-amp-programming",title:"CZ2002 Object Oriented Design & Programming",description:"AY20/21, Semester 1",section:"Teaching",handler:()=>{window.location.href="/teaching/AY2021-S1-CZ2002/"}},{id:"teaching-cx1115-introduction-to-ds-and-ai",title:"CX1115 Introduction to DS and AI",description:"AY20/21, Semester 2",section:"Teaching",handler:()=>{window.location.href="/teaching/AY2021-S2-CX1115/"}},{id:"teaching-cz4042-neural-networks-and-deep-learning",title:"CZ4042 Neural Networks and Deep Learning",description:"AY21/22, AY22/23, AY23/24",section:"Teaching",handler:()=>{window.location.href="/teaching/AY2122-S1-CZ4042/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%69%68%61%6F%30%31%39@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=68v21DIAAAAJ","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/randcogitation","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>